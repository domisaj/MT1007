---
title: "Logistic Regression in R"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Get data from a url
url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"

# Reading the data
data <- read.csv(url, header = FALSE)
```
<br>

We need to reformat the data.     

The data doesn't have column names.

<br> 
``` {r}
head(data)

# We can see that the data doesn't have column names

```
<br>

We have to add column names to the entire dataset.

<br>
``` {r}
colnames(data) = c(
  "age",
  "sex", # 0 = female, 1 = male
  "cp", # chest pain
  # 1 = typical angina,
  # 2 = atypical angina,
  # 3 = non-anginal pain,
  # 4 = asymptomatic
  "trestbps", # resting blood pressure (in mm Hg)
  "chol", # serum cholestoral in mg/dl
  "fbs",  # fasting blood sugar if less than 120 mg/dl, 1 = TRUE, 0 = FALSE
  "restecg", # resting electrocardiographic results
  # 1 = normal
  # 2 = having ST-T wave abnormality
  # 3 = showing probable or definite left ventricular hypertrophy
  "thalach", # maximum heart rate achieved
  "exang",   # exercise induced angina, 1 = yes, 0 = no
  "oldpeak", # ST depression induced by exercise relative to rest
  "slope", # the slope of the peak exercise ST segment
  # 1 = upsloping
  # 2 = flat
  # 3 = downsloping
  "ca", # number of major vessels (0-3) colored by fluoroscopy
  "thal", # this is short of thalium heart scan
  # 3 = normal (no cold spots)
  # 6 = fixed defect (cold spots during rest and exercise)
  # 7 = reversible defect (when cold spots only appear during exercise)
  "hd" # (the predicted attribute) - diagnosis of heart disease
  # 0 if less than or equal to 50% diameter narrowing
  # 1 if greater than 50% diameter narrowing
)

head(data)
# Can see the column names
```

``` {r}
str(data) # Inspect our data
```
<br>

We see that some columns which should be factors are not labelled as such, and there are also "?"s in the data. 

<br>
```{r}
# Have to change ?s to NAs
data[data == "?"] <- NA

# Change numeric columns to factors
data$sex <- as.factor(data$sex)
data$cp <- as.factor(data$cp)
data$fbs <- as.factor(data$fbs)
data$restecg <- as.factor(data$restecg)
data$exang <- as.factor(data$exang)
data$slope <- as.factor(data$slope)

# Clarify levels of sex column
levels(data$sex)
levels(data$sex) <- c("F", "M")
levels(data$sex)

# Clean up ?s
data$ca <- as.integer(data$ca) # thinks levels are strings, first convert to integers
data$ca <- as.factor(data$ca) # then convert to factor levels

data$thal <- as.integer(data$thal) # thinks levels are strings, convert to integers
data$thal <- as.factor(data$thal) # then convert to factors

# Replace 0 and 1 with "healthy" and "unhealthy"
data$hd <- ifelse(test = data$hd == 0, yes = "Healthy", no = "Unhealthy")
# Convert to factor
data$hd <- as.factor(data$hd) 

str(data)
```

# Determine how many rows have NA (missing data)

<br>

```{r}
nrow(data[is.na(data$ca) | is.na(data$thal),])
data[is.na(data$ca) | is.na(data$thal),]
```

<br>

Only 6 out of 303 rows have missing values. We can just remove them from the dataset as it's not that large of a percentage (2%)

<br>
``` {r}
nrow(data)
data <- data[!(is.na(data$ca) | is.na(data$thal)),]
nrow(data)
```

<br>

*"Now we can do some quality control by making sure all of the factor
levels are represented by people with and without heart disease (hd)."*

*"NOTE: We also want to exclude variables that only have 1 or 2 samples in a category since +/- one or two samples can have a large effect on the odds/log(odds)."*

<br>

```{r}
xtabs(~hd, data = data)
xtabs(~ hd + sex, data=data)
xtabs(~ hd + cp, data=data)
xtabs(~ hd + fbs, data=data)
xtabs(~ hd + restecg, data=data)
xtabs(~ hd + exang, data=data)
xtabs(~ hd + slope, data=data)
xtabs(~ hd + ca, data=data)
xtabs(~ hd + thal, data=data)
```

# Logistic Regression in R

<br>

Start with a very simple model, seeing is sex (female/male) is a good predictor of whether someone is healthy or unhealthy.

<br>

```{r}
# Look at raw data
xtabs(~ hd + sex, data = data)
```

<br>

We can see that most females fall in the healthy category while most males fall in the unhealthy category. 

Being female likely decreases the odds of being unhealthy. Being male likely increases the odds of being unhealthy. 

<br>

```{r}
logistic <- glm(hd ~ sex, data = data, family = "binomial")
summary(logistic)
```

<br> 

The intercept is the log(odds) a female will be unhealthy. 

<br>

```{r}
female.log.odds <- log(25/71)
female.log.odds
```

<br> 

"sexM is the log(odds ratio) that tells us that if a sample has sex = M, the odds of being unhealthy are, on a log scale, 1.27 times greater than if a sample has sex = F."

<br>

```{r}
male.log.odds.ratio <- log((112 / 89) / (25/71))
male.log.odds.ratio
```